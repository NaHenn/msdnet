{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nExample 05: Train a network for regression (tomography)\n=======================================================\n\nThis script trains a MS-D network for regression (i.e. denoising/artifact removal)\nRun generatedata.py first to generate required training data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import code\nimport msdnet\nimport glob\n\n# Define dilations in [1,10] as in paper.\ndilations = msdnet.dilations.IncrementDilations(10)\n\n# Create main network object for regression, with 100 layers,\n# [1,10] dilations, 5 input channels (5 slices), 1 output channel, using\n# the GPU (set gpu=False to use CPU)\nn = msdnet.network.MSDNet(100, dilations, 5, 1, gpu=True)\n\n# Initialize network parameters\nn.initialize()\n\n# Define training data\n# First, create lists of input files (low quality) and target files (high quality)\nflsin = sorted(glob.glob('tomo_train/lowqual/*.tiff'))\nflstg = sorted(glob.glob('tomo_train/highqual/*.tiff'))\n# Create list of datapoints (i.e. input/target pairs)\ndats = []\nfor i in range(len(flsin)):\n    # Create datapoint with file names\n    d = msdnet.data.ImageFileDataPoint(flsin[i],flstg[i])\n    # Add datapoint to list\n    dats.append(d)\n# Note: The above can also be achieved using a utility function for such 'simple' cases:\n# dats = msdnet.utils.load_simple_data('tomo_train/lowqual/*.tiff', 'tomo_train/highqual/*.tiff', augment=False)\n\n# Convert input slices to input slabs (i.e. multiple slices as input)\ndats = msdnet.data.convert_to_slabs(dats, 2, flip=True)\n# Augment data by rotating and flipping\ndats_augm = [msdnet.data.RotateAndFlipDataPoint(d) for d in dats]\n    \n\n# Normalize input and output of network to zero mean and unit variance using\n# training data images\nn.normalizeinout(dats)\n\n# Use image batches of a single image\nbprov = msdnet.data.BatchProvider(dats,1)\n\n# Define validation data (not using augmentation)\nflsin = sorted(glob.glob('tomo_val/lowqual/*.tiff'))\nflstg = sorted(glob.glob('tomo_val/highqual/*.tiff'))\ndatsv = []\nfor i in range(len(flsin)):\n    d = msdnet.data.ImageFileDataPoint(flsin[i],flstg[i])\n    datsv.append(d)\n# Note: The above can also be achieved using a utility function for such 'simple' cases:\n# datsv = msdnet.utils.load_simple_data('tomo_val/lowqual/*.tiff', 'tomo_val/highqual/*.tiff', augment=False)\n\n# Convert input slices to input slabs (i.e. multiple slices as input)\ndatsv = msdnet.data.convert_to_slabs(datsv, 2, flip=False)\n\n# Validate with Mean-Squared Error\nval = msdnet.validate.MSEValidation(datsv)\n\n# Use ADAM training algorithms\nt = msdnet.train.AdamAlgorithm(n)\n\n# Log error metrics to console\nconsolelog = msdnet.loggers.ConsoleLogger()\n# Log error metrics to file\nfilelog = msdnet.loggers.FileLogger('log_tomo_regr.txt')\n# Log typical, worst, and best images to image files\nimagelog = msdnet.loggers.ImageLogger('log_tomo_regr', onlyifbetter=True, chan_in=2)\n\n# Train network until program is stopped manually\n# Network parameters are saved in regr_params.h5\n# Validation is run after every len(datsv) (=256)\n# training steps.\nmsdnet.train.train(n, t, val, bprov, 'tomo_regr_params.h5',loggers=[consolelog,filelog,imagelog], val_every=len(datsv))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}